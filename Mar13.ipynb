{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35536a06-5647-42ae-8038-51a8938d3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "'''\n",
    "Assumptions;\n",
    "i.Independence of observations\n",
    "ii.Normality\n",
    "iii.Homogeneity of variances\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8a39a-5a8f-434c-bd66-0af2e8f6cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "'''\n",
    "Three types of ANOVAs:\n",
    "- One way ANOVA : This is used when there is one categorical independent variable  and one continuous dependent\n",
    "    variable. \n",
    "- Two way ANOVA : This is used when there are two categorical independent variables and one continuous dependent\n",
    "    variable. \n",
    "- Repeated measures ANOVA: his is used when there is one categorical independent variable and one continuous\n",
    "    dependent variable, but the dependent variable is measured multiple times within each level of the \n",
    "    independent variable.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da39cb-b0b0-4b2b-b057-fc6b8da51ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "'''\n",
    "The partitioning of variance in ANOVA refers to the process of dividing the total variance of a dependent\n",
    "variable into different components that are associated with different sources of variation. These components\n",
    "include the between-group variance, within-group variance, and total variance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9590484e-f180-4f3f-a0e7-40aa86e93187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 303.3333333333332\n",
      "SSE: 30.0\n",
      "SSR: 273.3333333333332\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create the data\n",
    "group1 = [4, 6, 8, 7, 5]\n",
    "group2 = [9, 11, 13, 10, 12]\n",
    "group3 = [15, 17, 19, 16, 18]\n",
    "data = group1 + group2 + group3\n",
    "groups = ['Group 1']*5 + ['Group 2']*5 + ['Group 3']*5\n",
    "\n",
    "# Fit the model\n",
    "model = ols('data ~ C(groups)', data={'data': data, 'groups': groups}).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the sums of squares\n",
    "SST = anova_table['sum_sq']['C(groups)']\n",
    "SSE = anova_table['sum_sq']['Residual']\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246bbd3-da5c-4beb-88f4-dbbad383e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create the ANOVA model\n",
    "model = ols('dependent_var ~ factor_1 + factor_2 + factor_1:factor_2', data=data_frame).fit()\n",
    "\n",
    "# calculate the main effects\n",
    "main_effects = sm.stats.anova_lm(model, typ=1)['sum_sq'][:-1]\n",
    "\n",
    "# calculate the interaction effect\n",
    "interaction_effect = sm.stats.anova_lm(model, typ=1)['sum_sq'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99ba31-85c9-455c-aadb-9889c9012b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "'''\n",
    "If we obtained an F-statistic of 5.23 and a p-value of 0.02 from a one-way ANOVA,\n",
    "It is likely that at least one of the groups has a different mean from the others.\n",
    "\n",
    "The F-statistic of 5.23 indicates the ratio of variance between the group means to variance within the groups. \n",
    "A larger F-statistic indicates greater differences between the group means relative to the variability within \n",
    "the groups. \n",
    "\n",
    "The p-value of 0.02 indicates the probability of observing such an F-statistic or more extreme under the \n",
    "assumption that the null hypothesis is true. Since the p-value is less than the significance level of 0.05, \n",
    "we can reject the null hypothesis and conclude that there is a significant difference between the group means.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1286091-75ae-4dd5-b3b2-cbed7109116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "'''\n",
    "methods of handling missing data:\n",
    "-pairwise deletion\n",
    "-mean substitution\n",
    "-maximum likelihood estimation\n",
    "-multiple imputation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2e02a-e807-4061-b778-1c6970b88d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "'''\n",
    "Post-hoc tests are used to make pairwise comparisons between groups after a significant difference\n",
    "has been found in an ANOVA. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c98a12-291b-47b3-aba1-32c066a2e19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic:  63.36004955545838\n",
      "P-value:  1.4314708003491508e-20\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "# Define the data\n",
    "diet_a = np.random.randint(2,12,50)\n",
    "diet_b = np.random.randint(3,19,50)\n",
    "diet_c = np.random.randint(2,8,50)\n",
    "\n",
    "# Perform the one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic: \", f_statistic)\n",
    "print(\"P-value: \", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1985dae-b98b-43a3-817f-aeb2f32a00e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum_sq    df         F    PR(>F)\n",
      "Program              0.205444   2.0  0.044145  0.835222\n",
      "Experience                NaN   1.0       NaN       NaN\n",
      "Program:Experience   5.603333   2.0  1.204022  0.282578\n",
      "Residual            60.500000  26.0       NaN       NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 1, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1900: RuntimeWarning: invalid value encountered in divide\n",
      "  F /= J\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a dataframe with the data\n",
    "data = {'Program': ['A']*10 + ['B']*10 + ['C']*10,\n",
    "        'Experience': ['Novice']*15 + ['Experienced']*15,\n",
    "        'Time': [10, 12, 9, 11, 10, 13, 8, 11, 10, 12,\n",
    "                 15, 16, 14, 17, 15, 18, 13, 16, 15, 17,\n",
    "                 20, 22, 21, 23, 22, 24, 19, 22, 21, 23]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('Time ~ Program + Experience + Program:Experience', data=df).fit()\n",
    "table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "704c16b1-ea58-4d23-82d0-aac8329f7fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic:  -3.031617200418805\n",
      "p-value:  0.002757729976398418\n",
      "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
      "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
      " (0 - 1)     77.038     0.000    75.536    78.539\n",
      " (1 - 0)    -77.038     0.000   -78.539   -75.536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, f_oneway, tukey_hsd\n",
    "\n",
    "# Generate some example data\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(75, 10, size=100)\n",
    "experimental_scores = np.random.normal(80, 10, size=100)\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores)\n",
    "print(\"t-statistic: \", t_stat)\n",
    "print(\"p-value: \", p_val)\n",
    "\n",
    "# Conduct post-hoc test (Tukey HSD)\n",
    "scores = np.concatenate([control_scores, experimental_scores])\n",
    "groups = np.concatenate([np.zeros(100), np.ones(100)])\n",
    "tukey_results = tukey_hsd(scores, groups)\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92cd6e77-1855-4a87-abb2-077aa443dc95",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# create a dataframe with sales data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m26\u001b[39m,\n\u001b[1;32m      9\u001b[0m                   \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m17\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m27\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m29\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m34\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m27\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m29\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m33\u001b[39m]}\n\u001b[0;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# conduct one-way ANOVA\u001b[39;00m\n\u001b[1;32m     14\u001b[0m f_stat, p_value \u001b[38;5;241m=\u001b[39m f_oneway(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m], df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m], df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    657\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    658\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#12\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# create a dataframe with sales data\n",
    "data = {'store': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "        'sales': [10, 12, 11, 14, 13, 15, 16, 17, 12, 14, 11, 13, 14, 16, 18, 19, 20, 22, 17, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
    "                  15, 16, 14, 18, 17, 16, 20, 22, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# conduct one-way ANOVA\n",
    "f_stat, p_value = f_oneway(df[df['store']=='A']['sales'], df[df['store']=='B']['sales'], df[df['store']=='C']['sales'])\n",
    "\n",
    "print('One-way ANOVA results:')\n",
    "print('F-statistic:', f_stat)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "# conduct post-hoc test (Tukey's HSD)\n",
    "posthoc = pairwise_tukeyhsd(df['sales'], df['store'], alpha=0.05)\n",
    "\n",
    "print('Post-hoc test results:')\n",
    "print(posthoc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
