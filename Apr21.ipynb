{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbadc73-4785-4245-894e-e763e7576970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "'''\n",
    "\n",
    "The k-Nearest Neighbors (KNN) algorithm is a simple and widely used supervised machine learning algorithm for\n",
    "classification and regression tasks. It is a non-parametric and instance-based learning algorithm. In KNN, \n",
    "the \"k\" refers to the number of nearest neighbors considered for making predictions or classifications.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8606f-9802-42e1-8b77-d88b292204c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "'''\n",
    "1.Odd vs. Even:\n",
    "    In binary classification problems, it's often recommended to use an odd value for \"k\" to avoid ties when voting\n",
    "    for the majority class. Ties can occur when the number of neighbors is even, leading to potential ambiguity in\n",
    "    the decision.\n",
    "\n",
    "2.Cross-Validation:\n",
    "    Use cross-validation techniques, such as k-fold cross-validation, to evaluate the performance of the model for\n",
    "    different values of \"k.\" This helps in selecting a value of \"k\" that generalizes well to unseen data.\n",
    "\n",
    "3.Rule of Thumb:\n",
    "    A common rule of thumb is to choose \"k\" as the square root of the number of data points in your training set.\n",
    "    However, this is a general guideline, and the optimal value may vary depending on the dataset and the problem.\n",
    "\n",
    "4.Experimentation:\n",
    "    Experiment with different values of \"k\" and observe how the model performs on a validation set or through \n",
    "    cross-validation. Plotting the model's performance against different values of \"k\" can help identify the optimal\n",
    "    value.\n",
    "\n",
    "5.Consider Dataset Size:\n",
    "    In general, for smaller datasets, it's advisable to use a smaller value of \"k\" (e.g., 3 or 5) to capture local \n",
    "    patterns. For larger datasets, a larger value of \"k\" may be appropriate.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39496522-9c37-4eb1-b61f-211c491cd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "'''\n",
    "For regression , KRegessor is used.The value is calculate by mean of the nearest neighbours of k.\n",
    "For classification, KClassifier is used.The output is obtained by the category whose count is more near to k.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574b0b6-058d-4a35-9603-dcee11750562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "'''\n",
    "Classifier:\n",
    "- confusion matrix\n",
    "- accuracy score\n",
    "- classification report\n",
    "\n",
    "Regressor:\n",
    "- R2 score\n",
    "- Mean Squared Error\n",
    "- Mean Absolute Error\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0cfdd-ee95-41c4-a7ad-06fae1ff47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "'''\n",
    "- Increased distance between points\n",
    "- Sparse Data\n",
    "- Increased computational complexity\n",
    "- Overfitiing\n",
    "- Increased sample  size requirements\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b91183-85d4-4f03-bd8e-1f16079f13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "'''\n",
    "Imputation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d651138-230b-4132-b2a3-875decf060c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "'''\n",
    "KNN classifier is used for classification tasks, where the goal is to assign instances to predefined\n",
    "classes or categories.\n",
    "\n",
    "KNN classifiers can be suitable for problems where the decision boundaries are not easily represented\n",
    "by simple linear models, and the underlying patterns are complex and nonlinear.\n",
    "\n",
    "KNN regressor is used for regression tasks, where the goal is to predict a continuous target variable.\n",
    "\n",
    "KNN regressors can be suitable for problems where the relationship between the features and the target \n",
    "variable is not easily represented by a simple linear model and involves complex, non-linear patterns.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ab526-a521-4dd0-b64f-d24596b79536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "'''\n",
    "Strengths of KNN:\n",
    "\n",
    "1. Simple and Intuitive:\n",
    "KNN is easy to understand and implement. Its simplicity makes it a good choice for quick prototyping \n",
    "and baseline models.\n",
    "2. Non-Parametric:\n",
    "KNN is non-parametric, meaning it does not make strong assumptions about the underlying distribution \n",
    "of the data. This flexibility allows it to adapt to a variety of data patterns.\n",
    "3. Effective for Non-Linear Relationships:\n",
    "KNN is effective in capturing complex and non-linear relationships in the data. It can handle decision \n",
    "boundaries that are not easily represented by simple linear models.\n",
    "4. No Training Phase:\n",
    "KNN does not have an explicit training phase. The model memorizes the training data, making it suitable\n",
    "for online learning scenarios where the data is constantly changing.\n",
    "\n",
    "Weaknesses of KNN:\n",
    "1. Computational Complexity:\n",
    "The main weakness of KNN is its computational cost. As the size of the dataset grows, the time needed to\n",
    "compute distances and find neighbors becomes significant. This can make KNN impractical for large datasets.\n",
    "2. Sensitive to Irrelevant Features:\n",
    "KNN is sensitive to irrelevant features, as all features are considered in the distance calculation. \n",
    "Feature scaling and selection techniques can help address this issue.\n",
    "3. Impact of Outliers:\n",
    "Outliers and noisy data can significantly affect KNN's performance. The algorithm may give undue influence \n",
    "to outliers when calculating distances, leading to suboptimal predictions.\n",
    "4. Curse of Dimensionality:\n",
    "In high-dimensional spaces, the distance between points increases, and the concept of proximity becomes less\n",
    "meaningful. This can degrade the performance of KNN in high-dimensional datasets, known as the \"curse of dimensionality.\"\n",
    "5. Choice of K:\n",
    "The choice of the hyperparameter \"k\" is critical. A small \"k\" can make the model sensitive to noise, while\n",
    "a large \"k\" may oversmooth the decision boundaries. Cross-validation or other validation techniques can help\n",
    "find an optimal \"k.\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfcb57-1038-4273-a6f8-805ce57a6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "'''\n",
    "Euclidean distance is the straight-line distance between two points in space. It is the length of the shortest \n",
    "path connecting the two points.\n",
    "\n",
    "Manhattan distance is the sum of the absolute differences between corresponding coordinates of two points. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b103018-44d8-499e-8bd1-af4d926a1b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "'''\n",
    "The goal of feature scaling is to ensure that all features contribute equally to the distance calculations \n",
    "when determining the nearest neighbors. In KNN, the algorithm relies on the distances between data points, \n",
    "and if features have different scales, it can lead to biased influence on the distance computations.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
